{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4499d9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No' 'Yes' nan]\n",
      "[0 1]\n",
      "['No' 'Yes' nan]\n",
      "[0 1]\n",
      "['Graduate' 'Not Graduate']\n",
      "[1 0]\n",
      "['Urban' 'Rural' 'Semiurban']\n",
      "[0 1 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loan_ID                    0\n",
       "Gender                    24\n",
       "Married                    0\n",
       "Dependents                25\n",
       "Education                  0\n",
       "Self_Employed              0\n",
       "ApplicantIncome            0\n",
       "CoapplicantIncome          0\n",
       "LoanAmount                 0\n",
       "Loan_Amount_Term           0\n",
       "Credit_History             0\n",
       "Property_Area              0\n",
       "Loan_Status              367\n",
       "ApplicantIncome_log        0\n",
       "CoApplicantIncome_log      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features (all columns except target)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(\"Loan dataset_classification.csv\")\n",
    "\n",
    "print(df[\"Married\"].unique())\n",
    "df[\"Married\"]=df[\"Married\"].fillna(df[\"Married\"].mode()[0])\n",
    "df[\"Married\"] = df[\"Married\"].map({\"No\": 0, \"Yes\": 1})\n",
    "print(df[\"Married\"].unique())\n",
    "\n",
    "\n",
    "print(df[\"Self_Employed\"].unique())\n",
    "df[\"Self_Employed\"]=df[\"Self_Employed\"].fillna(df[\"Self_Employed\"].mode()[0])\n",
    "df[\"Self_Employed\"] = df[\"Self_Employed\"].map({\"No\": 0, \"Yes\": 1})\n",
    "print(df[\"Self_Employed\"].unique())\n",
    "\n",
    "print(df[\"Education\"].unique())\n",
    "df[\"Education\"]=df[\"Education\"].fillna(df[\"Education\"].mode()[0])\n",
    "df[\"Education\"] = df[\"Education\"].map({\"Not Graduate\": 0, \"Graduate\": 1})\n",
    "print(df[\"Education\"].unique())\n",
    "\n",
    "print(df[\"Property_Area\"].unique())\n",
    "df[\"Property_Area\"]=df[\"Property_Area\"].fillna(df[\"Property_Area\"].mode()[0])\n",
    "df[\"Property_Area\"] = df[\"Property_Area\"].map({\"Urban\": 0, \"Rural\": 1,\"Semiurban\":2 })\n",
    "print(df[\"Property_Area\"].unique())\n",
    "\n",
    "df[\"ApplicantIncome\"] = df[\"ApplicantIncome\"].fillna(df[\"ApplicantIncome\"].median())\n",
    "df[\"CoapplicantIncome\"] = df[\"CoapplicantIncome\"].fillna(df[\"CoapplicantIncome\"].median())\n",
    "df[\"LoanAmount\"] = df[\"LoanAmount\"].fillna(df[\"LoanAmount\"].median())\n",
    "df[\"Loan_Amount_Term\"] = df[\"Loan_Amount_Term\"].fillna(df[\"Loan_Amount_Term\"].median())\n",
    "df[\"Credit_History\"] = df[\"Credit_History\"].fillna(0)\n",
    "\n",
    "# Add small value to avoid log(0) errors\n",
    "df[\"ApplicantIncome_log\"]= np.log(df[\"ApplicantIncome\"] + 1)\n",
    "df[\"CoApplicantIncome_log\"]= np.log(df[\"CoapplicantIncome\"] + 1)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36b1e9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Loan Status Distribution:\n",
      "Loan_Status\n",
      "Y    422\n",
      "N    192\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Loan Status by Gender:\n",
      "Loan_Status    N    Y  All\n",
      "Gender                    \n",
      "Female        37   75  112\n",
      "Male         150  339  489\n",
      "All          187  414  601\n",
      "\n",
      "==================================================\n",
      "\n",
      "Loan Status by Married Status:\n",
      "Loan_Status    N    Y  All\n",
      "Married                   \n",
      "0             79  134  213\n",
      "1            113  288  401\n",
      "All          192  422  614\n",
      "\n",
      "==================================================\n",
      "\n",
      "Loan Status by Education:\n",
      "Loan_Status    N    Y  All\n",
      "Education                 \n",
      "0             52   82  134\n",
      "1            140  340  480\n",
      "All          192  422  614\n",
      "\n",
      "==================================================\n",
      "\n",
      "Loan Status by Self Employment:\n",
      "Loan_Status      N    Y  All\n",
      "Self_Employed               \n",
      "0              166  366  532\n",
      "1               26   56   82\n",
      "All            192  422  614\n",
      "\n",
      "==================================================\n",
      "\n",
      "Loan Status by Property Area:\n",
      "Loan_Status      N    Y  All\n",
      "Property_Area               \n",
      "0               69  133  202\n",
      "1               69  110  179\n",
      "2               54  179  233\n",
      "All            192  422  614\n"
     ]
    }
   ],
   "source": [
    "# Show dependent variable (Loan_Status) count by categories\n",
    "print(\"Overall Loan Status Distribution:\")\n",
    "print(df[\"Loan_Status\"].value_counts())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Loan Status by Gender\n",
    "print(\"Loan Status by Gender:\")\n",
    "print(pd.crosstab(df[\"Gender\"], df[\"Loan_Status\"], margins=True))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Loan Status by Married\n",
    "print(\"Loan Status by Married Status:\")\n",
    "print(pd.crosstab(df[\"Married\"], df[\"Loan_Status\"], margins=True))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Loan Status by Education\n",
    "print(\"Loan Status by Education:\")\n",
    "print(pd.crosstab(df[\"Education\"], df[\"Loan_Status\"], margins=True))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Loan Status by Self_Employed\n",
    "print(\"Loan Status by Self Employment:\")\n",
    "print(pd.crosstab(df[\"Self_Employed\"], df[\"Loan_Status\"], margins=True))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Loan Status by Property_Area\n",
    "print(\"Loan Status by Property Area:\")\n",
    "print(pd.crosstab(df[\"Property_Area\"], df[\"Loan_Status\"], margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecd2aa83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after cleaning: (614, 15)\n",
      "Loan Status distribution:\n",
      "Loan_Status\n",
      "1    422\n",
      "0    192\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values in Loan_Status (drop rows with NaN in target)\n",
    "df = df.dropna(subset=[\"Loan_Status\"])\n",
    "\n",
    "# Encode target variable\n",
    "df[\"Loan_Status\"] = df[\"Loan_Status\"].map({\"Y\": 1, \"N\": 0})\n",
    "\n",
    "print(f\"Dataset shape after cleaning: {df.shape}\")\n",
    "print(f\"Loan Status distribution:\\n{df['Loan_Status'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0cf0e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (601, 11)\n",
      "Features: ['Gender', 'Married', 'Education', 'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History', 'Property_Area']\n",
      "Target distribution:\n",
      "Loan_Status\n",
      "1    414\n",
      "0    187\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare features (X) and target (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Select features for training\n",
    "feature_columns = [\"Gender\", \"Married\", \"Education\", \"Self_Employed\", \n",
    "                   \"ApplicantIncome\", \"CoapplicantIncome\", \"LoanAmount\", \n",
    "                   \"Loan_Amount_Term\", \"Credit_History\", \"Property_Area\"]\n",
    "\n",
    "# Encode Gender if not already done\n",
    "if df[\"Gender\"].dtype == 'object':\n",
    "    df[\"Gender\"] = df[\"Gender\"].map({\"Male\": 1, \"Female\": 0})\n",
    "    \n",
    "# Drop rows with any remaining missing values in features\n",
    "df_clean = df[feature_columns + [\"Loan_Status\"]].dropna()\n",
    "\n",
    "X = df_clean[feature_columns]\n",
    "y = df_clean[\"Loan_Status\"]\n",
    "\n",
    "print(f\"Final dataset shape: {df_clean.shape}\")\n",
    "print(f\"Features: {list(X.columns)}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29b28c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (480, 10)\n",
      "Testing set size: (121, 10)\n",
      "\n",
      "Training set target distribution:\n",
      "Loan_Status\n",
      "1    331\n",
      "0    149\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Testing set target distribution:\n",
      "Loan_Status\n",
      "1    83\n",
      "0    38\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Testing set size: {X_test.shape}\")\n",
    "print(f\"\\nTraining set target distribution:\\n{y_train.value_counts()}\")\n",
    "print(f\"\\nTesting set target distribution:\\n{y_test.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3aa3d432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully!\n",
      "Model coefficients: [-1.07940451e-01  5.11454135e-01  3.65336072e-01  7.70996340e-02\n",
      " -3.16343849e-06 -5.69132299e-06 -1.48647532e-03 -1.89705464e-04\n",
      "  2.11324226e+00  1.71016215e-01]\n",
      "Model intercept: -1.1488000209771758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JHAGAUT\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression Model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model trained successfully!\")\n",
    "print(f\"Model coefficients: {model.coef_[0]}\")\n",
    "print(f\"Model intercept: {model.intercept_[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cb2d83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7812 (78.12%)\n",
      "Testing Accuracy: 0.7273 (72.73%)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Confusion Matrix (Test Set):\n",
      "[[17 21]\n",
      " [12 71]]\n",
      "\n",
      "==================================================\n",
      "\n",
      "Classification Report (Test Set):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Not Approved (N)       0.59      0.45      0.51        38\n",
      "    Approved (Y)       0.77      0.86      0.81        83\n",
      "\n",
      "        accuracy                           0.73       121\n",
      "       macro avg       0.68      0.65      0.66       121\n",
      "    weighted avg       0.71      0.73      0.72       121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\n",
    "print(f\"Testing Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nConfusion Matrix (Test Set):\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nClassification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=[\"Not Approved (N)\", \"Approved (Y)\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb00c443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (981, 13)\n",
      "Missing Loan_Status values: 367\n",
      "\n",
      "Rows with missing Loan_Status:\n",
      "      Loan_ID Gender Married  ... Credit_History Property_Area Loan_Status\n",
      "614  LP001015   Male     Yes  ...            1.0         Urban         NaN\n",
      "615  LP001022   Male     Yes  ...            1.0         Urban         NaN\n",
      "616  LP001031   Male     Yes  ...            1.0         Urban         NaN\n",
      "617  LP001035   Male     Yes  ...            NaN         Urban         NaN\n",
      "618  LP001051   Male      No  ...            1.0         Urban         NaN\n",
      "..        ...    ...     ...  ...            ...           ...         ...\n",
      "976  LP002971   Male     Yes  ...            1.0         Urban         NaN\n",
      "977  LP002975   Male     Yes  ...            1.0         Urban         NaN\n",
      "978  LP002980   Male      No  ...            NaN     Semiurban         NaN\n",
      "979  LP002986   Male     Yes  ...            1.0         Rural         NaN\n",
      "980  LP002989   Male      No  ...            1.0         Rural         NaN\n",
      "\n",
      "[367 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load original dataset to find missing Loan_Status values\n",
    "df_original = pd.read_csv(\"Loan dataset_classification.csv\")\n",
    "\n",
    "print(f\"Original dataset shape: {df_original.shape}\")\n",
    "print(f\"Missing Loan_Status values: {df_original['Loan_Status'].isnull().sum()}\")\n",
    "print(f\"\\nRows with missing Loan_Status:\")\n",
    "missing_loan_status = df_original[df_original['Loan_Status'].isnull()]\n",
    "print(missing_loan_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2365eda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data for prediction...\n",
      "Preprocessing complete!\n",
      "Missing values after preprocessing:\n",
      "Gender               24\n",
      "Married               0\n",
      "Education             0\n",
      "Self_Employed         0\n",
      "ApplicantIncome       0\n",
      "CoapplicantIncome     0\n",
      "LoanAmount            0\n",
      "Loan_Amount_Term      0\n",
      "Credit_History        0\n",
      "Property_Area         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data with missing Loan_Status for prediction\n",
    "df_predict = df_original.copy()\n",
    "\n",
    "# Apply same preprocessing as training data\n",
    "print(\"Preprocessing data for prediction...\")\n",
    "\n",
    "# Handle categorical variables\n",
    "df_predict[\"Gender\"] = df_predict[\"Gender\"].map({\"Male\": 1, \"Female\": 0})\n",
    "df_predict[\"Married\"] = df_predict[\"Married\"].fillna(df_predict[\"Married\"].mode()[0])\n",
    "df_predict[\"Married\"] = df_predict[\"Married\"].map({\"No\": 0, \"Yes\": 1})\n",
    "df_predict[\"Self_Employed\"] = df_predict[\"Self_Employed\"].fillna(df_predict[\"Self_Employed\"].mode()[0])\n",
    "df_predict[\"Self_Employed\"] = df_predict[\"Self_Employed\"].map({\"No\": 0, \"Yes\": 1})\n",
    "df_predict[\"Education\"] = df_predict[\"Education\"].fillna(df_predict[\"Education\"].mode()[0])\n",
    "df_predict[\"Education\"] = df_predict[\"Education\"].map({\"Not Graduate\": 0, \"Graduate\": 1})\n",
    "df_predict[\"Property_Area\"] = df_predict[\"Property_Area\"].fillna(df_predict[\"Property_Area\"].mode()[0])\n",
    "df_predict[\"Property_Area\"] = df_predict[\"Property_Area\"].map({\"Urban\": 0, \"Rural\": 1, \"Semiurban\": 2})\n",
    "\n",
    "# Handle numerical variables\n",
    "df_predict[\"ApplicantIncome\"] = df_predict[\"ApplicantIncome\"].fillna(df_predict[\"ApplicantIncome\"].median())\n",
    "df_predict[\"CoapplicantIncome\"] = df_predict[\"CoapplicantIncome\"].fillna(df_predict[\"CoapplicantIncome\"].median())\n",
    "df_predict[\"LoanAmount\"] = df_predict[\"LoanAmount\"].fillna(df_predict[\"LoanAmount\"].median())\n",
    "df_predict[\"Loan_Amount_Term\"] = df_predict[\"Loan_Amount_Term\"].fillna(df_predict[\"Loan_Amount_Term\"].median())\n",
    "df_predict[\"Credit_History\"] = df_predict[\"Credit_History\"].fillna(0)\n",
    "\n",
    "print(\"Preprocessing complete!\")\n",
    "print(f\"Missing values after preprocessing:\\n{df_predict[feature_columns].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2c6d2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records to predict: 367\n",
      "Missing values in features: 0\n"
     ]
    }
   ],
   "source": [
    "# Handle remaining missing Gender values by filling with mode\n",
    "df_predict[\"Gender\"] = df_predict[\"Gender\"].fillna(df_predict[\"Gender\"].mode()[0])\n",
    "\n",
    "# Get indices where Loan_Status is missing\n",
    "missing_indices = df_predict[df_predict['Loan_Status'].isnull()].index\n",
    "\n",
    "# Prepare features for prediction\n",
    "X_missing = df_predict.loc[missing_indices, feature_columns]\n",
    "\n",
    "print(f\"Number of records to predict: {len(X_missing)}\")\n",
    "print(f\"Missing values in features: {X_missing.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "069c66e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions made for 367 records\n",
      "\n",
      "Prediction distribution:\n",
      "Approved (Y): 279\n",
      "Not Approved (N): 88\n",
      "\n",
      "First 10 predictions: ['Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'N', 'Y', 'Y']\n"
     ]
    }
   ],
   "source": [
    "# Predict missing Loan_Status values\n",
    "predictions = model.predict(X_missing)\n",
    "\n",
    "# Map predictions back to Y/N\n",
    "predictions_mapped = ['Y' if pred == 1 else 'N' for pred in predictions]\n",
    "\n",
    "print(f\"Predictions made for {len(predictions)} records\")\n",
    "print(f\"\\nPrediction distribution:\")\n",
    "print(f\"Approved (Y): {predictions.sum()}\")\n",
    "print(f\"Not Approved (N): {len(predictions) - predictions.sum()}\")\n",
    "print(f\"\\nFirst 10 predictions: {predictions_mapped[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7181024f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original missing Loan_Status: 367\n",
      "After prediction missing Loan_Status: 0\n",
      "\n",
      "Complete dataset shape: (981, 13)\n",
      "\n",
      "Loan Status distribution in complete dataset:\n",
      "Loan_Status\n",
      "Y    701\n",
      "N    280\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "Sample of records with predicted Loan_Status:\n",
      "================================================================================\n",
      "      Loan_ID  Gender Married  ... LoanAmount  Credit_History  Loan_Status\n",
      "614  LP001015    Male     Yes  ...      110.0             1.0            Y\n",
      "615  LP001022    Male     Yes  ...      126.0             1.0            Y\n",
      "616  LP001031    Male     Yes  ...      208.0             1.0            Y\n",
      "617  LP001035    Male     Yes  ...      100.0             NaN            N\n",
      "618  LP001051    Male      No  ...       78.0             1.0            Y\n",
      "619  LP001054    Male     Yes  ...      152.0             1.0            Y\n",
      "620  LP001055  Female      No  ...       59.0             1.0            Y\n",
      "621  LP001056    Male     Yes  ...      147.0             0.0            N\n",
      "622  LP001059    Male     Yes  ...      280.0             1.0            Y\n",
      "623  LP001067    Male      No  ...      123.0             1.0            Y\n",
      "\n",
      "[10 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Fill missing Loan_Status values with predictions\n",
    "df_complete = df_original.copy()\n",
    "df_complete.loc[missing_indices, 'Loan_Status'] = predictions_mapped\n",
    "\n",
    "print(f\"Original missing Loan_Status: {df_original['Loan_Status'].isnull().sum()}\")\n",
    "print(f\"After prediction missing Loan_Status: {df_complete['Loan_Status'].isnull().sum()}\")\n",
    "print(f\"\\nComplete dataset shape: {df_complete.shape}\")\n",
    "print(f\"\\nLoan Status distribution in complete dataset:\")\n",
    "print(df_complete['Loan_Status'].value_counts())\n",
    "\n",
    "# Display sample of predicted records\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Sample of records with predicted Loan_Status:\")\n",
    "print(\"=\"*80)\n",
    "print(df_complete.loc[missing_indices[:10], ['Loan_ID', 'Gender', 'Married', 'Education', \n",
    "                                               'ApplicantIncome', 'LoanAmount', 'Credit_History', \n",
    "                                               'Loan_Status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "962bcdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Complete dataset saved as 'Loan_dataset_complete_with_predictions.csv'\n",
      "\n",
      "Summary:\n",
      "- Total records: 981\n",
      "- Records with original Loan_Status: 614\n",
      "- Records with predicted Loan_Status: 367\n",
      "- Predicted Approvals (Y): 279 (76.0%)\n",
      "- Predicted Rejections (N): 88 (24.0%)\n"
     ]
    }
   ],
   "source": [
    "# Save the complete dataset with predictions\n",
    "df_complete.to_csv(\"Loan_dataset_complete_with_predictions.csv\", index=False)\n",
    "print(\"✓ Complete dataset saved as 'Loan_dataset_complete_with_predictions.csv'\")\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"- Total records: {len(df_complete)}\")\n",
    "print(f\"- Records with original Loan_Status: {len(df_original) - df_original['Loan_Status'].isnull().sum()}\")\n",
    "print(f\"- Records with predicted Loan_Status: {len(predictions)}\")\n",
    "print(f\"- Predicted Approvals (Y): {predictions.sum()} ({predictions.sum()/len(predictions)*100:.1f}%)\")\n",
    "print(f\"- Predicted Rejections (N): {len(predictions) - predictions.sum()} ({(len(predictions) - predictions.sum())/len(predictions)*100:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
